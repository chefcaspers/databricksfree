{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb45898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "CATALOG_NAME = 'gk_demo'\n",
    "SCHEMA_NAME = 'default'\n",
    "VOLUME_NAME = 'raw_data'\n",
    "TABLE_NAME = f'{CATALOG_NAME}.{SCHEMA_NAME}.all_events'\n",
    "\n",
    "# Create Unity Catalog objects\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG_NAME}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}\")\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}.{VOLUME_NAME}\")\n",
    "print(f\"✅ Unity Catalog objects ready\")\n",
    "\n",
    "# Source paths (your working approach)\n",
    "DATA_DIR = Path('../data')\n",
    "GZ_FILE = os.path.join(DATA_DIR, 'raw_events.json.gz')\n",
    "\n",
    "# Destination paths (in volume)\n",
    "VOLUME_PATH = f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}\"\n",
    "VOLUME_JSON_FILE = f\"{VOLUME_PATH}/raw_events.json\"\n",
    "\n",
    "def unzip_to_volume():\n",
    "    if not os.path.exists(VOLUME_JSON_FILE):\n",
    "        print(f\"Unzipping {GZ_FILE} to volume {VOLUME_JSON_FILE}...\")\n",
    "        with gzip.open(GZ_FILE, 'rb') as f_in, open(VOLUME_JSON_FILE, 'wb') as f_out:\n",
    "            f_out.write(f_in.read())\n",
    "        print(\"✅ Unzipped to volume\")\n",
    "    else:\n",
    "        print(f\"{VOLUME_JSON_FILE} already exists in volume. Skipping unzip.\")\n",
    "\n",
    "def main():\n",
    "    unzip_to_volume()\n",
    "    df = spark.read.json(VOLUME_JSON_FILE)\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(TABLE_NAME)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
