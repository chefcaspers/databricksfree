{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12a1b31",
   "metadata": {},
   "source": [
    "# Introduction to Agents in Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9c262a",
   "metadata": {},
   "source": [
    "Let's create an agent, __RefundAgent__ that identifies orders that are eligible for a refund based on the time it took to deliver the order.\n",
    "\n",
    "To do this we'll need to equip our agent with two tools:\n",
    "\n",
    "  1. __Order Details tool__: This tool will take an `order_id` as an input and return all the events associated with this order\n",
    "  2. __Location Timing tool__: This tool will take a `location` and retrieve the 50/75/99 percentile delivery times for that specific location\n",
    "\n",
    "We'll attach these tools to a tool capable LLM like `llama-3-3` in the Playground and test it out directly in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432f76e2",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "We will work through the following steps:   \n",
    "1. Initialize the catalog and volume and set up the data\n",
    "2. Define tools for the agent to use\n",
    "3. Use the playground to call the tools and test the agent\n",
    "4. Export the agent from the playground to a notebook\n",
    "\n",
    "This repo includes a zipped data file that contains two weeks of sample delivery data. We will start by unzipping the file and loading the data into a Delta table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d4a07c",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dcb65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import setup_catalog_and_volume, copy_raw_data_to_volume, initialize_events_table, drop_gk_demo_catalog\n",
    "\n",
    "# Drop existing catalog/volume/table if you need to start fresh\n",
    "# drop_gk_demo_catalog(spark)\n",
    "\n",
    "## 1. Setup the catalog and volume\n",
    "setup_catalog_and_volume(spark)\n",
    "\n",
    "## 2. Copy the raw data to the volume\n",
    "copy_raw_data_to_volume()\n",
    "\n",
    "## 3. Initialize the events table\n",
    "initialize_events_table(spark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
